{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QovT45u4cpGF"
   },
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объедини общие данные о фильмах [tmdb_5000_movies](https://files.sberdisk.ru/s/te4QbzdxKgsFQXA) и каст фильмов \n",
    "[tmdb_5000_credits](https://files.sberdisk.ru/s/H9oRuXQt5mFz3T9). Оставь в датасете только фильмы, которые вышли в \"релиз\".\\\n",
    "Выведи количество фильмов, оставшихся после фильтрации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "количество фильмов вышедших в релиз: 4795\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from files\n",
    "movies_dataset = pd.read_csv('../datasets/tmdb_5000_movies.csv')\n",
    "credits_dataset = pd.read_csv('../datasets/tmdb_5000_credits.csv')\n",
    "\n",
    "# Merge data using the movie_id as the identifier\n",
    "data = pd.merge(movies_dataset, credits_dataset, left_on='id', right_on='movie_id')\n",
    "\n",
    "# Filter data based on the \"status\" column with value \"Released\"\n",
    "dataset = data[data['status'] == 'Released'].copy()\n",
    "\n",
    "# Remove duplicate columns\n",
    "dataset.rename(columns={'title_x': 'title'}, inplace=True)\n",
    "dataset.drop(columns='title_y', inplace=True)\n",
    "dataset.drop(columns='movie_id', inplace=True)\n",
    "\n",
    "num_movies = len(dataset)\n",
    "print(\"количество фильмов вышедших в релиз:\", num_movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый наивный подход к рекомендации фильмов - рекомендовать фильмы с лучшими оценками пользователей. Фильмы, которые пользуются большей популярностью и признанием критиков, с большей вероятностью понравятся среднему зрителю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для справедливой оценки фильмов возьмем текущую рейтинговую систему IMDB (weighted rating (WR)), которая рассчитывается по формуле:\n",
    "$$WR = \\frac{v}{v + m} ⋅ R + \\frac{m}{v + m} ⋅ C$$ \n",
    "$v$ - количество голосов \\\n",
    "$m$ - количество голосов для включения в финальную таблицу \\\n",
    "$R$ - средняя оценка \\\n",
    "$C$ - средняя оценка всех фильмов \n",
    "\n",
    "Имплементируй функцию `weighted_rating`. С её помощью расcчитай рейтинг для каждого фильма и сохрани его в колонку `simple_score`.\\\n",
    "Выведи топ-5 фильмов по получившемуся рейтингу.\n",
    "> В качестве параметра $m$ выбери 95-й квантиль количества голосов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "топ-5 фильмов по рейтингу (simple_score):\n",
      "                   title  simple_score\n",
      "The Shawshank Redemption      7.849025\n",
      "         The Dark Knight      7.773990\n",
      "              Fight Club      7.761012\n",
      "               Inception      7.736496\n",
      "            Pulp Fiction      7.714726\n"
     ]
    }
   ],
   "source": [
    "def weighted_rating(movie, num_votes_for_table, average_rating_all_movies):\n",
    "    \"\"\"\n",
    "    Calculates the weighted rating for a movie using the IMDB weighted rating formula.\n",
    "\n",
    "    Arguments:\n",
    "        movie (pd.Series): Row of the movie data table.\n",
    "        num_votes_for_table (float): Number of votes to include the movie in the final table (m).\n",
    "        average_rating_all_movies (float): Average rating of all movies (C).\n",
    "\n",
    "    Returns:\n",
    "        float: Weighted rating for the movie.\n",
    "    \"\"\"\n",
    "    num_votes = movie['vote_count']  # number of votes (v)\n",
    "    average_rating = movie['vote_average']  # average rating (R)\n",
    "    return (num_votes / (num_votes + num_votes_for_table) * average_rating) + (num_votes_for_table / (num_votes + num_votes_for_table) * average_rating_all_movies)\n",
    "\n",
    "\n",
    "# Calculation of num_votes_for_table (m) and average_rating_all_movies (C)\n",
    "num_votes_for_table = dataset['vote_count'].quantile(0.95)\n",
    "average_rating_all_movies = dataset['vote_average'].mean()\n",
    "\n",
    "# Calculation of the rating for each movie and saving it in the \"simple_score\" column\n",
    "dataset['simple_score'] = dataset.apply(weighted_rating, args=(num_votes_for_table, average_rating_all_movies), axis=1)\n",
    "\n",
    "# Getting the top 5 movies by rating\n",
    "top_movies = dataset.nlargest(5, 'simple_score')\n",
    "\n",
    "print(\"топ-5 фильмов по рейтингу (simple_score):\")\n",
    "print(top_movies[['title', 'simple_score']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой подход к рекомендациям очень наивен, так как не учитывает информацию о самом фильме (жанр, режиссер, описание, актеры и т.п). \\\n",
    "**Content Based Filtering** (Фильтрация на основе содержания) - тип рекомендательной системы, которая предлагает пользователям похожие элементы на основе конкретного элемента. Общая идея этих рекомендательных систем заключается в том, что если человеку понравился определенный товар, то ему понравится и похожий на него товар."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../misc/images/content.png\" alt= “” width=\"300\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем алгоритм рекомендации на основе описания фильма. Для это требуется провести предобработку текста:\n",
    "* Замени NaN в описании фильма на пустой символ `''`\n",
    "* Удали все английские стоп слова (используй параметр `stop_words` в `TfidfVectorizer`)\n",
    "* Расcчитай [Tf-Idf](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) для описания фильма\n",
    "\n",
    "Выведи размер получившейся матрицы Tf-Idf\n",
    "\n",
    "> Для [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) используйте параметры по умолчанию "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер матрицы Tf-Idf: (4795, 20970)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Replacing NaN in movie overview with an empty string\n",
    "dataset['overview'].fillna('', inplace=True)\n",
    "\n",
    "# Creating an instance of TfidfVectorizer with English stop words removal\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Calculation of Tf-Idf for movie overview\n",
    "tfidf_matrix = vectorizer.fit_transform(dataset['overview'])\n",
    "\n",
    "print(\"размер матрицы Tf-Idf:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь тебе необходимо вычислить показатель сходства между описаниями фильмов. Используем косинусное расстояние, оно рассчитывается по формуле:\n",
    "$$cos(Θ) = \\frac{A ⋅ B}{∥A∥ ∥B∥} = \\frac{ Σ_{i=1}^{n} A_i ⋅ B_i } { \\sqrt{Σ_{i=1}^{n}A_{i}^{2}} ⋅ {\\sqrt{Σ_{i=1}^{n}B_{i}^{2}}}}$$\n",
    "Но поскольку мы использовали векторизатор TF-IDF на предыдущем шаге, достаточно вычислить скалярное произведение, которое и даст оценку косинусного сходства. Рассчитать его можно через [linear_kernel](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.linear_kernel.html). Результат сохрани в переменную `cosine_sim`.\n",
    "\n",
    "Выведи размер получившейся матрицы `cosine_sim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер матрицы `cosine_sim`: (4795, 4795)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Calculation of similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "print(\"размер матрицы `cosine_sim`:\", cosine_sim.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напиши функцию `get_recommendations`. На вход она принимает:\n",
    "* `movies_dataset` - датасет фильмов\n",
    "* `title` - название фильма, для которого мы будем искать похожие\n",
    "* `cosine_sim` - матрица расстояний между описаниями\n",
    "* `top_k` - топ-k cхожих фильмов\n",
    "\n",
    "Возвращает top_k названий фильмов, описание которых похоже на выбранный фильм.\\\n",
    "Выведи топ-5 фильмов для `title='Saving Private Ryan'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "топ-5 рекомендованных фильмов для 'Saving Private Ryan':\n",
      "   The Great Raid\n",
      "The Monuments Men\n",
      "The Expendables 2\n",
      "        Abandoned\n",
      "        The Train\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(movies_dataset, title, cosine_sim, top_k=10):\n",
    "    \"\"\"\n",
    "    Get recommendations of similar movies for a given movie.\n",
    "\n",
    "    Args:\n",
    "        movies_dataset (DataFrame): Dataset of movies.\n",
    "        title (str): Title of the movie for which recommendations are needed.\n",
    "        cosine_sim (ndarray): Matrix of distances between movie descriptions.\n",
    "        top_k (int, optional): Number of top recommended movies. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        Series: Titles of the top-K recommended movies.\n",
    "\n",
    "    Raises:\n",
    "        IndexError: If the movie title is not found in the dataset.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create an index for fast access to movies by title\n",
    "        indices = pd.Series(movies_dataset.index, index=movies_dataset['title']).drop_duplicates()\n",
    "        idx = indices[title]\n",
    "        # Get similarity scores for the given movie\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "        # Sort movies by similarity scores\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Get indexes of top-K movies\n",
    "        top_indexes = [score[0] for score in sim_scores[1:top_k+1]]\n",
    "\n",
    "        # Get titles of top-K movies\n",
    "        top_movies = movies_dataset['title'].iloc[top_indexes]\n",
    "\n",
    "        return top_movies\n",
    "    except KeyError:\n",
    "        raise IndexError(f\"Название фильма '{title}' не найдено в датасете.\")\n",
    "\n",
    "\n",
    "# Get recommendations for the movie 'Saving Private Ryan'\n",
    "try:\n",
    "    recommended_movies = get_recommendations(movies_dataset=dataset, title='Saving Private Ryan', cosine_sim=cosine_sim, top_k=5)\n",
    "    print(\"топ-5 рекомендованных фильмов для 'Saving Private Ryan':\")\n",
    "    print(recommended_movies.to_string(index=False))\n",
    "except IndexError as e:\n",
    "    print(str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один подход к построению рекомендательной системы - подход на основе сходства между пользователями. Этот подход называется **Collaborative Filtering** (Коллаборативная фильтрация).\n",
    "<center><img src=\"../misc/images/all.png\" alt= “” width=\"600\" height=\"700\"></center>\n",
    "Коллаборативная фильтрация - это тип рекомендательной системы, которая использует поведение и предпочтения похожих пользователей для рекомендации товаров или продуктов конкретному пользователю. Система собирает данные о прошлом поведении пользователей, такие как покупки, рейтинги и отзывы, и анализирует их для выявления закономерностей и сходства между пользователями. На основе этих закономерностей система рекомендует товары, которые понравились или были приобретены другими такими же пользователями в прошлом.\n",
    "\n",
    "Для реализации Коллаборативной фильтрации нам потребуются оценки пользователей [ratings](../datasets/ratings.csv).\n",
    "\n",
    ">userId - id пользователя \\\n",
    "movieId - id фильма \\\n",
    "rating - оценка фильма (от 0 до 5)\\\n",
    "timestamp - время оценки\n",
    "\n",
    "\n",
    "Воспользуйся библиотекой [surprise](https://surpriselib.com/) для обучения модели оценки рейтинга фильма [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD). Выведи средние значения 'RMSE', 'MAE' на кросс-валидации с параметрами `cv=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "средний RMSE на кросс-валидации: 0.8954165095312632\n",
      "средний MAE на кросс-валидации: 0.6895805121725338\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load ratings data\n",
    "ratings = pd.read_csv('../datasets/ratings.csv')\n",
    "\n",
    "# Initialize Reader object\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# Load data into Dataset object\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Initialize SVD model\n",
    "model = SVD()\n",
    "\n",
    "# Perform cross-validation with cv=5\n",
    "cv_results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5)\n",
    "\n",
    "print('средний RMSE на кросс-валидации:', np.mean(cv_results['test_rmse']))\n",
    "print('средний MAE на кросс-валидации:', np.mean(cv_results['test_mae']))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
